---
aliases: []
tags: [microsimulation, data-driven, multiple_imputation, knn, pocf]
author: "Ribeiro C"
URL: "https://link.springer.com/content/pdf/10.1007/s10462-021-09963-5.pdf"
title: "Ribeiro 2021 A data-driven missing value imputation approach."
type: "literature"
status: "nascent, in-progress, gardening"
year: "2021-11-01"
---

# Key Points

> What are they key takeaways from this literature
- Data driven missing imputation is a highly flexible if expensive method of imputation. 
- This paper proposes an ensemble of imputation techniques assessed by cross validation in order to more flexibly fill missing values. It can handle various data types (categorical, continous) but can be naive for highly missing data.
-  Applies method to ELSA data assessing in two ways. First method evalutes how analyses change with varying imputation. Second method uses synthetic population removing some values and comparing imputation to ground truth
-  Prevnext imputation perform best but is rarely applicable. Global mean is always applicable but performs poorly. Nearest neighbour is a good middle ground.  
-  Briefly suggests methods for balancing highly imbalanced variables. Uses underestimation before bootstrapping UBB and balanced random forest BRF methods to try and better impute rare attributes such as having cancer. BRF seems to perform better. This is useful for highly imbalanced classes where nearest neighbour may simply not do anything and always choose the default case.

# Motivation

> Why was this literature written what problem is it addressing?
- missing data in datasets etc. Due to data distributions, type (MCAR/MAR/MNAR), pattern (monotone/ swiss cheese etc.), the proportion of missing data, and the available information to inform imputation. 
- Most imputation techniques are bespoke to the dataset. A user can introduce bias by assuming the wrong imputation strategy. This paper aims to make this a purely data driven decision. 5 MI methods are used choosing the best according to data characteristics. 

# Background

> What previous work has been done towards this problem?
- Several studies have review MI methods but focus on specific data features (categorical, numeric, binary) with smaller datasets. This paper uses a larger mixed state.
-  MI is assessed either using sensetivity analysis /jackknifing bootstrapping etc. Second method is using a synthetic population as a ground truth. This paper uses both. Real data from ELSA and estimate every known value in the dataset. Random forest classification used to evalute models generated by datasets with each method. 
![[Screenshot 2021-11-01 at 17.17.46.png]]


# Methods

> What methods were used? How do they address any issues?
- ELSA dataset is used. One every 4 years collects biomedical data as an interview and series of tests. Not suitable as a ML dataset so have been adapted.
- base dataset  involved simplification of a number of issues. missing data as one value rather than several. Only used 8th wave of ELSA. fused all nurse-data datasets( 2, 4, 6, 8) and removing those who did not participate in wave 8 each dataset had n=7097.
- a lot of cleaning of redundant variables. repeat measurements were averaged. reduce 1041 features down to 44. 
- one shot encoding for disease variables. 10 age related diseases used Angina, Arthiritis etc. these variables combine several questions. E.g. two variables for a heart attack in a previous wave or the past 2 years specifically. Combined into an absorbing state (0 if never had a heart attack, 1 if ever had a heart attack). They followed methodology from (1).


- using 5 imputation methods here and an algorithm to combine them.
- global mean/mode. Simply impute features using the variable mean/mode. Simply but limited.
- age based mean/mode. Extension to stratify the global mean by age. A 60 year old would take the mean value of all complete 60 year olds
- Last observation carried forward (LOCF). Simply take the last complete measurement from an individual and replace it. Cant do this if theres no previous value so does remove some data. Also issues of lack of poor estimtion.
- Last and next combined. Similar to the above method but combines measurements from both directions. Gives better estimation than LOCF but requires more data. 
- knn. choose features from k closest complete individuals via some performance metric. k=7 limited number of features due to curse of dimensionality.
-  data driven approach uses 5-fold cross validation. 1 fold is assumed missing and imputed using the remaining 4. Error is either continuous or 0/1 for binary measures. Methods are ranked on their average error. 1 is best 5 is worst. Each method is used to impute the feature in descending order. If the rank 1 imputation cant be used it uses rank 2 and so on. 
-  This approach is costly but is flexible being able to handle a variety of different imputation scenarios. It may be naive and always choose a poor imputation method for highly missing data.

- Imputation methods are assessed by comparing differences in fitted analyses to imputed datasets. how does the regression change? Second approach is using a synthetic dataset, removing some values, and imputing them for comparison with the ground truth. 

- Class imbalancing can be a problem here. Used undersampling methods to bring rare health conditions up to 1:1 ratio of having to not having. used undersampling before bootsrapping (UBB) and balanced random forest (BRF). Can assess imbalance using imbalance ratio (number of majority / number of minority class members)

# Results

> What was the outcome of the research? Was it successful?
- prevnext 7nn and locf performed bset. 7nn was applicable in a lot more cases though. mean/mode methods were virtually always applicable but poor accuracy. 
- 7nn prev prevnext are resistant to class imbalances.
# Glossary
Any new words should be defined here or reference from the main glossary in /Utility/glossary.  If there isnt a file in the main glossary you can still tag it here and create it later.
1. 

# References
1. Feature selection for the classification of longitudinal human ageing data.  
	In: IEEE International Conference on Data Mining Workshops (ICDMW). IEEE, pp 739â€“746